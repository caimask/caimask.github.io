---
layout: post
title: Apache Kafka
tags: [Kafka, Kinesis, Data Stream]
author: caimask
---

### Apache Kafka 란?
아파치 카프카(Apache Kafka)는 아파치 소프트웨어 재단이 스칼라로 개발한 오픈 소스 메시지 브로커 프로젝트이다. 이 프로젝트는 실시간 데이터 피드를 관리하기 위해 통일된, 높은 처리량, 낮은 지연시간을 지닌 플랫폼을 제공하는 것이 목표이다. 요컨대 분산 트랜잭션 로그로 구성된, 상당히 확장 가능한 pub/sub 메시지 큐로 정의할 수 있으며, 스트리밍 데이터를 처리하기 위한 기업 인프라를 위한 고부가 가치 기능이다.

참조 : [위키 아파치 카프카](https://ko.wikipedia.org/wiki/%EC%95%84%ED%8C%8C%EC%B9%98_%EC%B9%B4%ED%94%84%EC%B9%B4)



### To Use Kafka
Kafka 의 사용에 앞서서 Kafka 가 어떤 것이며, 어떤 기능을 하는지 이해는 것이 중요하다. 앞에서는 단순한 정의를 기술한 것이라면 여기에서는 Kafka 의 기능과 동작에 대해서 이해한 것을 정리해 보자.

Kafka는 세 가지 주요 기능을 결합하여 이벤트 스트리밍 종단간 전달 기능을 구현 할 수 있다.

1. To **publish** (write) and **subscribe to** (read) streams of events, including continuous import/export of your data from other systems.

2. To **store** streams of events durably and reliably for as long as you want.

3. To **process** streams of events as they occur or retrospectively.

Kafka API

1. The Admin API  : to manage and inspect topics, brokers, and other Kafka objects.

2. The Producer API  : to publish (write) a stream of events to one or more Kafka topics.

3. The Consumer API  : to subscribe to (read) one or more topics and to process the stream of events produced to them.

4. The Kafka Streams API : to implement stream processing applications and microservices. 

It provides higher-level functions to process event streams, including transformations, stateful operations like aggregations and joins, windowing, processing based on event-time, and more. Input is read from one or more topics in order to generate output to one or more topics, effectively transforming the input streams to output streams.

5. The Kafka Connect API : to build and run reusable data import/export connectors that consume (read) or produce (write) streams of events from and to external systems and applications so they can integrate with Kafka. 

For example, a connector to a relational database like PostgreSQL might capture every change to a set of tables. However, in practice, you typically don't need to implement your own connectors because the Kafka community already provides hundreds of ready-to-use connectors.

참조 : [Kafka Introduction](https://kafka.apache.org/intro)


### Kafka VS Kinesis



참조 : [링크](https://devidea.tistory.com/68)
